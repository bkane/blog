---
title: "From Scratch... uh, Again"
author: "Ben Kane"
date: "2023-05-15"
categories: [learning]
format:
  html:
    code-fold: false
---

Okay now I *know* we've done this before: making a neural network from scratch. This course is a wacky mess sometimes. It's a new 2022 edition of an "old" (2019?) course that's partially based on a book. It's clumsy and that really shows with this lesson.

Having said that, the reinforcement of learning to make a model from scratch means it's sinking in better each time. I'm still making mistakes when I try to write this stuff out myself first so there's definitely still value in the repetition.

# Not All Repetition

There's new stuff too! More practice with Pandas. More rubber-hits-the-road details dealing with handling missing data. The short answer? Don't throw it out! You can't keep that `NaN` value in there, but you can easily fill it in with the mode of that column. What's more, a framework like fastai will automatically create an extra bool column to indicate if the related column was filled in or not. The fact that data was originally missing could itself be a useful feature!

We also saw how to handle continuous data with long-tail distributions (take the log!) as well as how to turn non-numerical data into a number (dummy variable categorization!). A neat thing to note is when data *is* stored as a number, but doesn't actually represent a continuous range (like the Class=1,2, or 3 in Titanic passengers). Lastly, we saw the importance of normalizing data with big ranges to allow for easier optimization.

# And the rest

Then there was a lot of work creating the neural network, training it, creating a network with hidden layers, and so forth. It was useful. I will need to do more of this to actually practice this stuff.

# What's Tripping Me Up Today

This blog is more of a journal of what I'm currently struggling to understand. If anything is helpful looking back, it may be this. Plus it's kinda helpful just to get it written down, because maybe some of these things I actually have answers for now that the lesson is finished.

- Oddity: when we did this example in Excel, we only did `Pclass_0` and `Pclass_1`, with Pclass = 2 being implied if the first two are false. We can do this with `pd.get_dummies` too, with a `drop_first=True` flag. However, if we do this, then we need to include a constant term in our linear equations too. If we fully specify the dummy variables, we don’t need this constant. I don’t totally understand why this is.

- In the Titanic example, we notice that the first column, ‘Age’, has a much bigger magnitude range than the other columns. I'm told this will make it "hard to optimize." (which we can solve by normalizing the values) 
But why? shouldn’t gradient descent handle this gracefully? sure it will be off at first, but eventually the weight of that column will just be smaller relatively speaking, no?


- If we use a sigmoid function to smush predictions to [0,1] after the fact, then the optimizer doesn’t need to work really hard to get things to exactly 1 or 0 - it can be content with this bigger or smaller values.
This took me a little bit, but I think this means we can have a higher learning rate and still have it be stable. The optimizer doesn't need to try to nail a '1' to indicate "survived". It can generate a 1.4, which is smushed to 1, and have a loss of zero. Without it, a prediction of 1.4 and another of 0.6 would both have equal loss values (I think).


- What about categories that only appear in test or real world data? (for dummy variables)
For this, I think we need an "Other" category. Frameworks like fastai might already do this?

- Tensor shapes. Still. We made a deep neural net with two hidden layers, so that meant expanding the coefficients to be a matrix instead of a vector. Every time, I was able to work my way to an understanding, but it still isn't intuitive yet. The idea of "number of outputs of layer n must match the number of inputs at layer n + 1" is fine, but whenever I start thinking about the matrix multiplication and what these matrices represent, I get bogged down quickly.

- When manually creating some of these neural network examples, there were things like `-0.3` and `/n_hidden` which Jeremy described as "fiddly" to find values to "get it to train". I'm not sure what this means or what something training vs not training looks like.


# Bonus Tidbits

- We expanded our predictions vector by one dimension to have a shape like `[713, 1]`. This is called a rank 2 tensor (matrix) with a “*trailing unit axis*”.

- NOTEBOOK TIP: there is a shortcut to split a code cell into a new cell by line. This effectively allows you to kinda of ‘debug’ and go line by line to see how it all works.

- Interesting result: the linear model, the two layer model, and the deep model all resulted in the same effective accuracy on the limited Titanic data set.
